<!DOCTYPE html>
<html lang="en" data-theme="dark">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Cognitive Parsimony Theory — Lumen Labs</title>
<link rel="icon" type="image/png" href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAABmElEQVR4nNWXsYrCQBCGjYIiQrpACAjXCTbXpbBNWpvb2sInyFU+Tt7A3pfwDXyENOkDdzP4BXK5nIbEuJ7wgSy78/87O5lsRqP/+MtP744wFiag/52hRVVkJriCJwTCEgLGXOaMHy28EHxhJYRCJGyFD9gyFjLHZ00/IxJgys7WCOyEAyKxYCBm7MCciDW6dtpVfE56NwTVXe2FVDgLmVBAxljKHJ81G2LMu4i/sZOEXR4R+7pDwVzD2ohY7UyQ9iULNaWfwqWFcJ0Law/EWt49DgrOI3UJAbIO4iUZMRJiejcLk8pdc36m486bMmGIqbEXt3bvky6fc+wrXnKsxf6dhfzaQFY43bcsuLYUxNyhMWsyoF0spGjSB4qXpMRWDbcu7lAgEQ7PAxg4EztCy6ka0PPXfq4tVbtan8q/9UTEaAQ/6iC/vtH0OdW+bh58/tU6MGio1uSlDFg/ArtFaP0xfJVGZLcVY8Ley6iSBXuvY0zYu5BUTNi7ktVM2LmUVkzYu5ZXTNj7MGkw8vxPsz/MPP/jdKjfN9N3qN87msOSAAAAAElFTkSuQmCC">
<link href="https://fonts.googleapis.com/css2?family=Playfair+Display:ital,wght@0,400;0,500;0,700;1,400&family=Manrope:wght@300;400;500;600;700&display=swap" rel="stylesheet">
<script>
window.MathJax = {
  tex: { inlineMath: [['$','$']], displayMath: [['$$','$$']] },
  svg: { fontCache: 'global' }
};
</script>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-svg.js"></script>
<style>
[data-theme="dark"] {
  --bg: #06070a; --fg: #e5e1d8; --accent: #F1B82F; --muted: #6e6b63;
  --surface: #0e0f13; --card-bg: #0d0e12; --card-border: rgba(255,255,255,0.06);
  --input-border: rgba(255,255,255,0.08);
  --dim: #3a3830;
  --opt-bg: rgba(241,184,47,0.08); --opt-border: rgba(241,184,47,0.25);
  --learn-bg: rgba(241,184,47,0.04); --learn-border: rgba(241,184,47,0.15);
  --dizzy-bg: rgba(255,100,100,0.06); --dizzy-border: rgba(255,100,100,0.2);
  --amb-bg: rgba(255,255,255,0.03); --amb-border: rgba(255,255,255,0.1);
}
[data-theme="light"] {
  --bg: #f4f2ed; --fg: #1a1a1e; --accent: #b8860b; --muted: #6b6860;
  --surface: #eae7e0; --card-bg: #ffffff; --card-border: rgba(0,0,0,0.08);
  --input-border: rgba(0,0,0,0.1);
  --dim: #c5c0b5;
  --opt-bg: rgba(184,134,11,0.08); --opt-border: rgba(184,134,11,0.25);
  --learn-bg: rgba(184,134,11,0.04); --learn-border: rgba(184,134,11,0.15);
  --dizzy-bg: rgba(200,60,60,0.06); --dizzy-border: rgba(200,60,60,0.15);
  --amb-bg: rgba(0,0,0,0.02); --amb-border: rgba(0,0,0,0.08);
}

* { margin: 0; padding: 0; box-sizing: border-box; }

body {
  background: var(--bg); color: var(--fg);
  font-family: 'Manrope', sans-serif;
  line-height: 1.85; font-size: 1.02rem; font-weight: 300;
  transition: background 0.45s, color 0.45s;
}

/* Grain */
body::after {
  content: ''; position: fixed; inset: 0;
  background-image: url("data:image/svg+xml,%3Csvg viewBox='0 0 512 512' xmlns='http://www.w3.org/2000/svg'%3E%3Cfilter id='n'%3E%3CfeTurbulence type='fractalNoise' baseFrequency='0.75' numOctaves='4' stitchTiles='stitch'/%3E%3C/filter%3E%3Crect width='100%25' height='100%25' filter='url(%23n)' opacity='0.04'/%3E%3C/svg%3E");
  pointer-events: none; z-index: 9999;
}

/* Layout - offset right so left margin has room for annotations */
.paper-container {
  max-width: 680px;
  margin: 0 auto 0 calc(50% - 180px);
  padding: 80px 40px 120px 40px;
  position: relative;
}
@media (max-width: 1100px) {
  .paper-container {
    margin: 0 auto;
    padding: 60px 24px 100px;
  }
}

/* Back link */
.back-link {
  display: inline-flex; align-items: center; gap: 8px;
  font-size: 0.82rem; font-weight: 500; color: var(--muted);
  text-decoration: none; letter-spacing: 0.04em;
  margin-bottom: 64px; transition: color 0.3s;
}
.back-link:hover { color: var(--accent); }
.back-link svg { width: 14px; height: 14px; }

/* Title block */
.paper-tag {
  font-size: 0.78rem; font-weight: 600; letter-spacing: 0.12em;
  text-transform: uppercase; color: var(--accent); margin-bottom: 24px;
}
.paper-title {
  font-family: 'Playfair Display', serif;
  font-size: clamp(2.2rem, 4vw, 3rem); font-weight: 400;
  line-height: 1.15; letter-spacing: -0.02em;
  margin-bottom: 12px; color: var(--fg);
}
.paper-subtitle {
  font-family: 'Playfair Display', serif;
  font-size: 1.15rem; font-style: italic;
  color: var(--accent); margin-bottom: 32px;
}
.paper-meta {
  font-size: 0.82rem; color: var(--muted); margin-bottom: 48px;
  padding-bottom: 48px; border-bottom: 1px solid var(--card-border);
}
.paper-meta span { color: var(--fg); font-weight: 500; }

/* Section headings */
h2 {
  font-family: 'Playfair Display', serif;
  font-size: 1.6rem; font-weight: 400; color: var(--fg);
  margin: 72px 0 24px; letter-spacing: -0.01em;
  padding-top: 32px; border-top: 1px solid var(--card-border);
}
h2:first-of-type { border-top: none; padding-top: 0; }

h3 {
  font-family: 'Manrope', sans-serif;
  font-size: 1.08rem; font-weight: 600; color: var(--fg);
  margin: 48px 0 16px; letter-spacing: 0.01em;
}

h4 {
  font-family: 'Manrope', sans-serif;
  font-size: 0.95rem; font-weight: 600; color: var(--accent);
  margin: 32px 0 12px;
}

/* Body text */
p { margin-bottom: 20px; }

strong { font-weight: 600; color: var(--fg); }

em { color: var(--fg); }

/* Lists */
ul, ol {
  margin: 0 0 20px 24px;
}
li { margin-bottom: 10px; }
li strong { color: var(--fg); }

/* Equations */
.equation {
  margin: 32px 0;
  padding: 24px 32px;
  background: var(--surface);
  border: 1px solid var(--card-border);
  border-radius: 8px;
  text-align: center;
  overflow-x: auto;
}
.equation mjx-container {
  max-width: 100% !important;
  overflow-x: auto !important;
}
.equation mjx-container svg {
  max-width: 100% !important;
  height: auto !important;
}
.equation.boxed {
  border-color: rgba(241,184,47,0.2);
  border-width: 1px;
  border-left: 3px solid var(--accent);
}
.eq-label {
  display: block; text-align: right;
  font-size: 0.75rem; color: var(--muted); margin-top: 8px;
}

/* Margin annotations */
.margin-ref {
  color: var(--accent); cursor: pointer;
  border-bottom: 1px dashed var(--accent);
  position: relative; display: inline;
  transition: color 0.2s;
}
.margin-ref:hover { color: #fff; }

.margin-popup {
  display: none; position: fixed;
  width: 220px; padding: 18px;
  background: var(--card-bg); border: 1px solid var(--card-border);
  border-radius: 8px; z-index: 10000;
  font-size: 0.8rem; line-height: 1.6;
  color: var(--muted);
  box-shadow: 0 12px 40px rgba(0,0,0,0.5);
}
.margin-popup .popup-title {
  font-weight: 600; color: var(--fg); font-size: 0.78rem;
  text-transform: uppercase; letter-spacing: 0.08em;
  margin-bottom: 8px; display: block;
}
.margin-popup .popup-link {
  color: var(--accent); font-size: 0.75rem;
  text-decoration: none; display: inline-flex;
  align-items: center; gap: 4px; margin-top: 8px;
}


/* For narrow screens, show popup below */


/* Definition terms */
.def-term {
  color: var(--accent); cursor: help;
  border-bottom: 1px dotted rgba(241,184,47,0.4);
  position: relative; display: inline;
}
.def-term:hover { border-bottom-color: var(--accent); }
.def-popup {
  display: none; position: fixed;
  width: 230px; padding: 18px;
  background: var(--card-bg); border: 1px solid var(--accent);
  border-radius: 8px; z-index: 10000;
  box-shadow: 0 12px 40px rgba(0,0,0,0.5);
}
.def-popup .def-symbol {
  font-family: 'Playfair Display', serif;
  font-size: 1.4rem; color: var(--accent);
  margin-bottom: 4px; display: block;
}
.def-popup .def-name {
  font-weight: 600; color: var(--fg); font-size: 0.82rem;
  margin-bottom: 8px; display: block;
}
.def-popup .def-desc {
  font-size: 0.8rem; color: var(--muted); line-height: 1.55;
}



/* Figures */
.figure-container {
  margin: 40px 0;
  padding: 32px;
  background: var(--surface);
  border: 1px solid var(--card-border);
  border-radius: 10px;
}
.figure-container > svg {
  width: 100%; height: auto; display: block;
  max-height: 500px;
}
.figure-caption mjx-container {
  display: inline !important;
  font-size: 1em !important;
}
.figure-caption mjx-container svg {
  width: auto !important;
  height: 1em !important;
  display: inline !important;
  vertical-align: -0.1em;
}
mjx-container {
  overflow-x: auto !important;
}
.figure-caption {
  margin-top: 20px; font-size: 0.82rem; color: var(--muted);
  line-height: 1.6; border-top: 1px solid var(--card-border);
  padding-top: 16px;
}
.figure-caption strong { color: var(--fg); }

/* Tables */
.table-container {
  margin: 32px 0;
  overflow-x: auto;
}
.table-container table {
  width: 100%; border-collapse: collapse;
  font-size: 0.88rem;
}
.table-container th {
  text-align: left; padding: 12px 16px;
  border-bottom: 2px solid var(--accent);
  font-weight: 600; color: var(--fg);
  font-size: 0.82rem; letter-spacing: 0.04em;
}
.table-container td {
  padding: 10px 16px;
  border-bottom: 1px solid var(--card-border);
  color: var(--muted);
}
.table-container tr:nth-child(even) td {
  background: rgba(255,255,255,0.015);
}
.table-container td:first-child {
  color: var(--accent); font-weight: 500;
  font-family: 'Playfair Display', serif;
}
.table-caption {
  font-size: 0.82rem; color: var(--muted); margin-top: 12px;
}

/* Quadrant cards */
.quadrant-grid {
  display: grid; grid-template-columns: 1fr 1fr;
  gap: 12px; margin: 24px 0;
}
.quadrant-card {
  padding: 24px; border-radius: 8px;
  border: 1px solid;
}
.quadrant-card h5 {
  font-size: 0.92rem; font-weight: 700;
  margin-bottom: 4px;
}
.quadrant-card .q-pi {
  font-size: 0.82rem; font-style: italic;
  margin-bottom: 10px; opacity: 0.8;
}
.quadrant-card p {
  font-size: 0.82rem; line-height: 1.55;
  margin: 0; opacity: 0.85;
}
.q-optimal { background: var(--opt-bg); border-color: var(--opt-border); color: #c9a62c; }
.q-learning { background: var(--learn-bg); border-color: var(--learn-border); color: #a89030; }
.q-dizzy { background: var(--dizzy-bg); border-color: var(--dizzy-border); color: #cc6666; }
.q-ambiguous { background: var(--amb-bg); border-color: var(--amb-border); color: #8a8880; }

/* Disambiguation cards */
.disambig-grid {
  display: grid; grid-template-columns: 1fr 1fr 1fr;
  gap: 12px; margin: 24px 0;
}
.disambig-card {
  padding: 20px; border-radius: 8px;
  background: var(--surface); border: 1px solid var(--card-border);
  text-align: center;
}
.disambig-card h5 {
  font-size: 0.95rem; font-weight: 700; margin-bottom: 12px;
}
.disambig-card .d-row {
  font-size: 0.82rem; color: var(--muted); margin-bottom: 4px;
}
.disambig-card .d-state {
  font-size: 0.82rem; font-style: italic; margin-top: 12px;
  padding-top: 12px; border-top: 1px solid var(--card-border);
}

/* Decision cycle */
.cycle-grid {
  display: grid; grid-template-columns: 1fr 1fr;
  gap: 16px; margin: 24px 0;
}
.cycle-card {
  padding: 20px 24px; border-radius: 8px;
  border: 1px solid var(--card-border);
}
.cycle-card h5 {
  font-size: 0.88rem; font-weight: 700; margin-bottom: 8px;
}
.cycle-card p {
  font-size: 0.82rem; color: var(--muted); margin: 0; line-height: 1.55;
}
.cycle-card .cycle-arrow {
  font-size: 0.72rem; color: var(--accent); margin-top: 8px;
  font-weight: 600;
}
.c-attend { border-color: rgba(241,184,47,0.2); background: rgba(241,184,47,0.04); }
.c-predict { border-color: rgba(100,150,255,0.2); background: rgba(100,150,255,0.04); }
.c-act { border-color: rgba(100,200,130,0.2); background: rgba(100,200,130,0.04); }
.c-learn { border-color: rgba(255,120,120,0.2); background: rgba(255,120,120,0.04); }

/* Ramanujan levels */
.ram-levels {
  margin: 24px 0;
}
.ram-level {
  display: flex; justify-content: space-between; align-items: center;
  padding: 16px 20px; border-radius: 8px; margin-bottom: 8px;
  border: 1px solid var(--card-border);
}
.ram-level:nth-child(1) { background: rgba(241,184,47,0.03); }
.ram-level:nth-child(2) { background: rgba(241,184,47,0.06); }
.ram-level:nth-child(3) { background: rgba(241,184,47,0.09); }
.ram-level:nth-child(4) { background: rgba(241,184,47,0.12); }
.ram-level .ram-title { font-weight: 600; font-size: 0.88rem; color: var(--fg); }
.ram-level .ram-desc { font-size: 0.82rem; color: var(--muted); margin-top: 2px; }
.ram-level .ram-cq { font-weight: 700; color: var(--accent); font-size: 0.88rem; white-space: nowrap; margin-left: 16px; }

/* CQ table special */
.cq-table td:first-child { font-family: 'Manrope', sans-serif; }

/* Blockquote / callout */
.callout {
  margin: 32px 0; padding: 24px 28px;
  border-left: 3px solid var(--accent);
  background: rgba(241,184,47,0.04);
  border-radius: 0 8px 8px 0;
  font-style: italic; color: var(--muted);
}

/* Failure mode */
.failure-mode {
  margin: 8px 0 20px;
  padding: 12px 20px;
  background: rgba(255,100,100,0.04);
  border-left: 2px solid rgba(255,100,100,0.3);
  border-radius: 0 6px 6px 0;
  font-size: 0.9rem; color: var(--muted);
}

/* References section */
.ref-list {
  counter-reset: ref;
}
.ref-item {
  display: flex; gap: 12px;
  font-size: 0.88rem; color: var(--muted);
  margin-bottom: 16px; line-height: 1.6;
}
.ref-num {
  flex-shrink: 0; width: 24px;
  color: var(--accent); font-weight: 600;
  font-size: 0.82rem;
}
.ref-item em { font-style: italic; }

/* Footer */
.paper-footer {
  margin-top: 80px; padding-top: 32px;
  border-top: 1px solid var(--card-border);
  text-align: left; font-size: 0.82rem; color: var(--muted);
}
.paper-footer a {
  color: var(--accent); text-decoration: none;
  border-bottom: 1px solid transparent;
  transition: border-color 0.3s;
}
.paper-footer a:hover { border-bottom-color: var(--accent); }

/* Scroll smooth */
html { scroll-behavior: smooth; }

/* Selection color */
::selection { background: rgba(241,184,47,0.25); color: #fff; }

/* Theme toggle */
.theme-toggle {
  position: fixed; top: 32px; left: 32px;
  width: 52px; height: 30px; border-radius: 15px;
  border: 1px solid var(--card-border); background: var(--surface);
  cursor: pointer; z-index: 1000; padding: 0;
  transition: border-color 0.3s, background 0.3s;
}
.theme-toggle:hover { border-color: var(--accent); }
.toggle-knob {
  display: block; width: 22px; height: 22px; border-radius: 50%;
  background: var(--accent); margin: 3px;
  transition: transform 0.3s; font-size: 13px;
  line-height: 22px; text-align: center;
}
[data-theme="dark"] .toggle-knob { transform: translateX(0); }
[data-theme="light"] .toggle-knob { transform: translateX(22px); }

/* Light mode grain reduction */
[data-theme="light"] body::after { opacity: 0.5; mix-blend-mode: multiply; }

/* Light mode SVG adjustments */
[data-theme="light"] .figure-container svg text { transition: fill 0.3s; }

/* Transitions for theme switch */
.paper-container, .equation, .figure-container, .table-container,
.disambig-card, .cycle-card, .ram-level, .failure-mode, .callout,
.margin-popup, .def-popup, .back-link, h2, h3, h4, p, li, td, th {
  transition: background 0.45s, color 0.45s, border-color 0.45s;
}

@media (max-width: 768px) {
  .theme-toggle { top: 20px; left: 20px; }
}

/* Light mode popup shadows */
[data-theme="light"] .margin-popup,
[data-theme="light"] .def-popup {
  box-shadow: 0 4px 16px rgba(0,0,0,0.06);
  border-color: rgba(0,0,0,0.1);
}
[data-theme="light"] .def-popup {
  border-color: var(--accent);
}

/* Light mode figure overrides */
[data-theme="light"] .figure-container {
  background: #f0ede6;
  border-color: rgba(0,0,0,0.08);
}

/* Figure SVG text - darken for readability */
[data-theme="light"] .figure-container > svg text[fill="#e5e1d8"] { fill: #1a1a1e; }
[data-theme="light"] .figure-container > svg text[fill="#6e6b63"] { fill: #4a4840; }
[data-theme="light"] .figure-container > svg text[fill="#F1B82F"] { fill: #8a6d08; }
[data-theme="light"] .figure-container > svg text[fill="#cc6666"] { fill: #a03030; }
[data-theme="light"] .figure-container > svg text[fill="#7cb87c"] { fill: #2a7a2a; }
[data-theme="light"] .figure-container > svg text[fill="#c9a62c"] { fill: #7a6510; }
[data-theme="light"] .figure-container > svg text[fill="#8a8880"] { fill: #4a4840; }
[data-theme="light"] .figure-container > svg text[fill="#8a8040"] { fill: #5a5020; }
[data-theme="light"] .figure-container > svg text[fill="#8a6060"] { fill: #6a3030; }
[data-theme="light"] .figure-container > svg text[fill="#6a6860"] { fill: #3a3830; }
[data-theme="light"] .figure-container > svg text[fill="#a89040"] { fill: #6a5a18; }

/* SVG lines and strokes */
[data-theme="light"] .figure-container > svg line[stroke="#e5e1d8"] { stroke: #1a1a1e; }
[data-theme="light"] .figure-container > svg line[stroke="#6e6b63"] { stroke: #4a4840; }
[data-theme="light"] .figure-container > svg line[stroke="#F1B82F"] { stroke: #8a6d08; }
[data-theme="light"] .figure-container > svg line[stroke="#cc6666"] { stroke: #a03030; }
[data-theme="light"] .figure-container > svg line[stroke="#7cb87c"] { stroke: #2a7a2a; }
[data-theme="light"] .figure-container > svg path[stroke="#F1B82F"] { stroke: #8a6d08; }
[data-theme="light"] .figure-container > svg path[stroke="#cc6666"] { stroke: #a03030; }

/* SVG rects - lighten backgrounds */
[data-theme="light"] .figure-container > svg rect[fill="rgba(255,255,255,0.05)"] { fill: rgba(0,0,0,0.04); }
[data-theme="light"] .figure-container > svg rect[fill="rgba(241,184,47,0.08)"] { fill: rgba(184,134,11,0.08); }
[data-theme="light"] .figure-container > svg rect[fill="rgba(241,184,47,0.12)"] { fill: rgba(184,134,11,0.1); }
[data-theme="light"] .figure-container > svg rect[fill="rgba(241,184,47,0.15)"] { fill: rgba(184,134,11,0.12); }
[data-theme="light"] .figure-container > svg rect[fill="rgba(100,200,130,0.08)"] { fill: rgba(30,120,30,0.08); }
[data-theme="light"] .figure-container > svg rect[stroke="#6e6b63"] { stroke: #4a4840; }
[data-theme="light"] .figure-container > svg rect[stroke="#F1B82F"] { stroke: #8a6d08; }
[data-theme="light"] .figure-container > svg rect[stroke="rgba(241,184,47,0.3)"] { stroke: rgba(138,109,8,0.3); }
[data-theme="light"] .figure-container > svg rect[stroke="rgba(100,200,130,0.3)"] { stroke: rgba(30,120,30,0.3); }

/* SVG arrow markers - use JS to swap, but also set via CSS where possible */
[data-theme="light"] .figure-container > svg marker path[fill="#e5e1d8"] { fill: #1a1a1e; }
[data-theme="light"] .figure-container > svg marker path[fill="#F1B82F"] { fill: #8a6d08; }
[data-theme="light"] .figure-container > svg marker path[fill="#6e6b63"] { fill: #4a4840; }
[data-theme="light"] .figure-container > svg marker path[fill="#cc6666"] { fill: #a03030; }
[data-theme="light"] .figure-container > svg marker path[fill="#7cb87c"] { fill: #2a7a2a; }

/* Figure 2 quadrant backgrounds for light mode */
[data-theme="light"] .figure-container > svg rect[fill="rgba(255,100,100,0.06)"] { fill: rgba(180,50,50,0.08); }
[data-theme="light"] .figure-container > svg rect[fill="rgba(241,184,47,0.05)"] { fill: rgba(184,134,11,0.07); }
[data-theme="light"] .figure-container > svg rect[fill="rgba(255,255,255,0.025)"] { fill: rgba(0,0,0,0.03); }
[data-theme="light"] .figure-container > svg rect[fill="rgba(241,184,47,0.09)"] { fill: rgba(184,134,11,0.1); }
[data-theme="light"] .figure-container > svg line[stroke="rgba(255,255,255,0.08)"] { stroke: rgba(0,0,0,0.1); }

/* Figure 3 trajectory quadrant backgrounds */
[data-theme="light"] .figure-container > svg rect[fill="rgba(255,100,100,0.06)"] { fill: rgba(180,50,50,0.06); }
[data-theme="light"] .figure-container > svg rect[fill="rgba(241,184,47,0.06)"] { fill: rgba(184,134,11,0.06); }
[data-theme="light"] .figure-container > svg rect[fill="rgba(255,255,255,0.03)"] { fill: rgba(0,0,0,0.03); }
[data-theme="light"] .figure-container > svg rect[fill="rgba(241,184,47,0.08)"] { fill: rgba(184,134,11,0.08); }

/* Figure 3 trajectory circle */
[data-theme="light"] .figure-container > svg circle[fill="#F1B82F"] { fill: #8a6d08; }

/* Quadrant card colors in light mode */
[data-theme="light"] .q-optimal { background: rgba(184,134,11,0.08); border-color: rgba(184,134,11,0.2); color: #6a5010; }
[data-theme="light"] .q-learning { background: rgba(184,134,11,0.05); border-color: rgba(184,134,11,0.15); color: #6a5010; }
[data-theme="light"] .q-dizzy { background: rgba(180,50,50,0.05); border-color: rgba(180,50,50,0.15); color: #8a2020; }
[data-theme="light"] .q-ambiguous { background: rgba(0,0,0,0.03); border-color: rgba(0,0,0,0.08); color: #4a4840; }

/* Disambig cards */
[data-theme="light"] .disambig-card { background: #f0ede6; border-color: rgba(0,0,0,0.08); }

/* Cycle cards */
[data-theme="light"] .c-attend { border-color: rgba(184,134,11,0.2); background: rgba(184,134,11,0.05); }
[data-theme="light"] .c-predict { border-color: rgba(60,90,180,0.2); background: rgba(60,90,180,0.05); }
[data-theme="light"] .c-act { border-color: rgba(40,140,70,0.2); background: rgba(40,140,70,0.05); }
[data-theme="light"] .c-learn { border-color: rgba(180,60,60,0.2); background: rgba(180,60,60,0.05); }

/* Ram levels */
[data-theme="light"] .ram-level { border-color: rgba(0,0,0,0.06); }
[data-theme="light"] .ram-level:nth-child(1) { background: rgba(184,134,11,0.04); }
[data-theme="light"] .ram-level:nth-child(2) { background: rgba(184,134,11,0.07); }
[data-theme="light"] .ram-level:nth-child(3) { background: rgba(184,134,11,0.10); }
[data-theme="light"] .ram-level:nth-child(4) { background: rgba(184,134,11,0.13); }

/* Failure mode */
[data-theme="light"] .failure-mode { background: rgba(180,50,50,0.04); border-left-color: rgba(180,50,50,0.25); }

/* Callout */
[data-theme="light"] .callout { background: rgba(184,134,11,0.06); border-left-color: var(--accent); }

/* Equation blocks */
[data-theme="light"] .equation { background: #ebe8e0; border-color: rgba(0,0,0,0.06); }
[data-theme="light"] .equation.boxed { border-left-color: var(--accent); }
</style>
<script type="text/javascript">
    (function(c,l,a,r,i,t,y){
        c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
        t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
        y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
    })(window, document, "clarity", "script", "vooonq2mdo");
</script>
</head>
<body>
<button class="theme-toggle" id="themeToggle" aria-label="Toggle theme">
  <span class="toggle-knob" id="toggleKnob"></span>
</button>
<div class="paper-container">

<a href="index.html" class="back-link">
  <svg viewBox="0 0 16 16" fill="none" stroke="currentColor" stroke-width="1.5"><path d="M10 3L5 8l5 5"/></svg>
  Back to Lumen Labs
</a>

<h1 class="paper-title">Cognitive Parsimony Theory</h1>
<div class="paper-subtitle">Why Consciousness is a Constrained Optimization Problem</div>
<div class="paper-meta">
  written by <span>Harry Gandhi</span> &nbsp;|&nbsp; February 20, 2026<br>
  Created with the assistance of Claude (Anthropic)
</div>

<!-- ═══ ABSTRACT ═══ -->
<h2>Abstract</h2>

<p>Today&#8217;s most advanced AI systems&#8202;&#8212;&#8202;large language models, vision transformers, multimodal architectures&#8202;&#8212;&#8202;are extraordinarily capable within their training distribution. They can draft legal briefs, generate photorealistic images, and beat grandmasters at chess. Yet they fail in ways that no conscious being would: they cannot reliably generalize to novel situations, they lack the ability to know what they don&#8217;t know, and they process the world through statistical correlation rather than understanding.</p>

<p>We believe this gap is not merely an engineering problem. It is a theoretical one. Current AI architectures lack a formal account of what it means to efficiently process experience&#8202;&#8212;&#8202;the very thing that consciousness appears to do. Without such an account, scaling alone will not produce general intelligence.</p>

<p>This white paper introduces <strong>Cognitive Parsimony Theory (CPT)</strong>, a mathematical framework that defines consciousness as the optimization of predictive efficiency. The core quantity is the <strong>Parsimony Index</strong> (<span class="def-term">$\pi$<span class="def-popup"><span class="def-symbol">&#960;</span><span class="def-name">Parsimony Index</span><span class="def-desc">The core optimization target. Ratio of free energy (prediction error) to salience-weighted sensory information. Low &#960; = efficient, conscious-like processing.</span></span></span>):</p>

<div class="equation boxed">$$\pi = \frac{F}{\text{Sn}}$$<span class="eq-label">(1)</span></div>

<p>where <span class="def-term">$F$<span class="def-popup"><span class="def-symbol">F</span><span class="def-name">Free Energy</span><span class="def-desc">Prediction error plus model complexity. The numerator of &#960;. Systems reduce F by building better world models or acting on the environment.</span></span></span> is free energy (prediction error) and <span class="def-term">$\text{Sn}$<span class="def-popup"><span class="def-symbol">Sn</span><span class="def-name">Sensory Information</span><span class="def-desc">Salience-weighted Shannon information. The denominator of &#960;. Not raw data volume but relevant, well-weighted information from all sensory channels.</span></span></span> is salience-weighted sensory information. A system that minimizes $\pi$ builds accurate world models while learning what information matters&#8202;&#8212;&#8202;and this dual optimization, we argue, is what gives rise to consciousness.</p>

<p>Critically, the theory addresses what we call the <strong>Climbing Problem</strong>&#8202;&#8212;&#8202;the question of why some systems ascend from simple information processing to rich, general intelligence, while others remain fixed at their initial level of complexity. Existing frameworks like the <span class="margin-ref">Free Energy Principle<span class="margin-popup"><span class="popup-title">Free Energy Principle (FEP)</span>Karl Friston&#8217;s framework proposing that all living systems minimize free energy&#8202;&#8212;&#8202;prediction error plus model complexity. Powerful for homeostasis, but doesn&#8217;t explain ascent.<a class="popup-link" href="https://doi.org/10.1038/nrn2787" target="_blank" rel="noopener">Friston, 2010 &#8599;</a></span></span> explain how systems maintain their current state, but not how they climb to higher states. Minimizing $\pi$ provides the upward pressure: once prediction errors are low, the only way to further reduce $\pi$ is to seek richer, more informative experience.</p>

<p>The full theory extends beyond $\pi$ to include integration (<span class="def-term">$\varphi$<span class="def-popup"><span class="def-symbol">&#966;</span><span class="def-name">Integration</span><span class="def-desc">Borrowed from IIT. Measures integrated information&#8202;&#8212;&#8202;how much the whole exceeds the sum of its parts. Not the definition of consciousness, but a necessary correlate.</span></span></span>), which measures information binding, and counterfactual capacity (<span class="def-term">$C_{\text{capacity}}$<span class="def-popup"><span class="def-symbol">C<sub>capacity</sub></span><span class="def-name">Counterfactual Capacity</span><span class="def-desc">Measures response repertoire richness. A conscious brain produces complex, differentiated responses; an unconscious brain produces stereotyped waves.</span></span></span>), which measures responsiveness:</p>

<div class="equation boxed">$$\text{Consciousness} \;\propto\; \frac{1}{\pi} \times \varphi \times C_{\text{capacity}}$$<span class="eq-label">(2)</span></div>

<p>The theory makes falsifiable predictions, provides a quantitative metric for measuring consciousness (the Consciousness Quotient, tested through Ramanujan-style mathematical insight problems), and offers a concrete direction for next-generation AGI architecture.</p>

<!-- ═══ SECTION 1: LIMITS OF CURRENT AI ═══ -->
<h2>The Limits of Current AI</h2>

<h3>What Large Language Models Actually Do</h3>

<p>Large language models (LLMs) like GPT-4, Claude, and Gemini are, at their core, next-token predictors. Given a sequence of text, they predict what comes next. Through this deceptively simple objective&#8202;&#8212;&#8202;applied at enormous scale across trillions of tokens&#8202;&#8212;&#8202;they develop remarkable capabilities: fluent language generation, code synthesis, mathematical reasoning, and even rudimentary planning.</p>

<p>But the mechanism underlying these capabilities is fundamentally statistical. An LLM does not understand that fire is hot; it has learned that the token &#8220;hot&#8221; is statistically likely to follow &#8220;fire is.&#8221; This distinction becomes decisive when we ask the system to generalize beyond its training distribution. Consider the failure modes that persist even in frontier models:</p>

<ul>
<li><strong>Brittle generalization.</strong> LLMs excel at tasks resembling their training data and degrade on problems requiring genuine novelty.</li>
<li><strong>No meta-cognition.</strong> LLMs cannot reliably distinguish what they know from what they don&#8217;t. They hallucinate with the same confidence they use to state facts.</li>
<li><strong>No grounded understanding.</strong> Language and vision models process symbols that refer to the world, but they have no experience of the world itself.</li>
<li><strong>No intrinsic motivation.</strong> LLMs do not seek information, explore their environment, or develop preferences. They respond to prompts.</li>
</ul>

<h3>The Deeper Problem: World Models Without Worlds</h3>

<p>The limitations above reflect a fundamental gap. Current AI systems build world models but do so without inhabiting a world. They have no ongoing stream of experience that they must make sense of in real time, no sensory apparatus whose information they must learn to weight and prioritize, and no prediction errors that carry consequences.</p>

<p>In biological systems, the pressure to efficiently process a continuous stream of experience appears to be precisely what gives rise to general intelligence. A mouse navigating a novel environment is solving an optimization problem in real time: it must predict what it will encounter, attend to the information that matters, and update its model when surprised. The mouse that does this most efficiently survives.</p>

<p>LLMs face no such pressure. We argue that this gap cannot be closed by scaling, adding modalities, or more clever prompting. It requires a fundamentally different optimization objective.</p>

<h3>World Models: Closer, But Still Incomplete</h3>

<p>A new generation of architectures has begun to address the limitations of pure language models by building explicit world models&#8202;&#8212;&#8202;internal representations of environment dynamics that support prediction and planning. Two of the most prominent are JEPA and DreamerV3.</p>

<p><strong>Joint Embedding Predictive Architecture (<span class="margin-ref">JEPA<span class="margin-popup"><span class="popup-title">JEPA</span>Yann LeCun&#8217;s framework for predicting abstract representations of future states rather than raw pixels. Development has been overwhelmingly visual (I-JEPA, V-JEPA).<a class="popup-link" href="https://openreview.net/pdf?id=BZ5a1r-kVsf" target="_blank" rel="noopener">LeCun, 2022 &#8599;</a></span></span>).</strong> LeCun&#8217;s JEPA framework predicts abstract representations of future states rather than raw pixels, allowing models to focus on semantically meaningful features while discarding irrelevant detail. However, JEPA&#8217;s development has been overwhelmingly visual, and it lacks a formal account of <em>why</em> a system should seek richer information; it provides better representations but no optimization pressure toward curiosity or integration.</p>

<p><strong><span class="margin-ref">DreamerV3<span class="margin-popup"><span class="popup-title">DreamerV3</span>Hafner et al.&#8217;s model-based RL agent that learns a recurrent state-space model (RSSM) and trains policies by imagining future trajectories. Masters 150+ diverse tasks with fixed hyperparameters.<a class="popup-link" href="https://doi.org/10.1038/s41586-025-08744-2" target="_blank" rel="noopener">Hafner et al., 2025 &#8599;</a></span></span>.</strong> Hafner et al.&#8217;s Dreamer line learns a recurrent state-space model from experience and trains policies by imagining future trajectories in latent space. DreamerV3 is impressively general&#8202;&#8212;&#8202;it masters over 150 diverse tasks with fixed hyperparameters. Yet Dreamer&#8217;s world model is fundamentally a task-specific reinforcement learning tool: it learns dynamics in service of maximizing external reward, not in service of efficient experience processing.</p>

<p><strong>The common limitation.</strong> Both JEPA and Dreamer share three fundamental constraints that CPT addresses:</p>

<ul>
<li><strong>Modality-specific design.</strong> CPT&#8217;s formulation&#8202;&#8212;&#8202;$\pi = F/\text{Sn}$, where $\text{Sn} = \sum_i w_i \cdot I(s_i)$&#8202;&#8212;&#8202;is defined over arbitrary sensory channels. The same equation applies whether $s_i$ comes from a camera, a microphone, a LiDAR sensor, or an electromagnetic antenna.</li>
<li><strong>No intrinsic drive toward richer experience.</strong> CPT&#8217;s denominator ($\text{Sn}$) provides exactly this: once $F$ is low, the only way to further reduce $\pi$ is to increase $\text{Sn}$&#8202;&#8212;&#8202;driving curiosity and sensory expansion as emergent behaviors.</li>
<li><strong>No account of consciousness or integration.</strong> CPT embeds world modeling within a broader framework connecting prediction ($F$), attention ($\text{Sn}$), integration ($\varphi$), and responsiveness ($C_{\text{capacity}}$).</li>
</ul>

<h3>Other Approaches and Their Limitations</h3>

<p><strong>The <span class="margin-ref">Free Energy Principle (FEP)<span class="margin-popup"><span class="popup-title">Ref [6]</span>Friston, K. (2010). The free-energy principle: A unified brain theory? <em>Nature Reviews Neuroscience</em>, 11(2), 127&#8211;138.<a class="popup-link" href="https://doi.org/10.1038/nrn2787" target="_blank" rel="noopener">View paper &#8599;</a></span></span>.</strong> Karl Friston&#8217;s FEP proposes that all living systems minimize free energy&#8202;&#8212;&#8202;prediction error plus model complexity. This is powerful for understanding homeostasis, but it explains how systems <em>maintain</em> their current state, not how they <em>ascend</em> to higher states. A thermostat minimizes free energy. So does a rock. We call this the <strong>Climbing Problem</strong>.</p>

<p><strong><span class="margin-ref">Integrated Information Theory (IIT)<span class="margin-popup"><span class="popup-title">Ref [12, 17, 18]</span>Tononi&#8217;s IIT proposes consciousness corresponds to integrated information (&#966;). Elegant formalism but descriptive, not prescriptive. Computing &#966; exactly is NP-hard.<a class="popup-link" href="https://doi.org/10.1186/1471-2202-5-42" target="_blank" rel="noopener">Tononi, 2004 &#8599;</a></span></span>.</strong> Giulio Tononi&#8217;s IIT proposes that consciousness corresponds to integrated information ($\varphi$). It provides an elegant formalism but is descriptive rather than prescriptive: it tells us how to measure consciousness, not how to build it.</p>

<p><strong><span class="margin-ref">Global Workspace Theory (GWT)<span class="margin-popup"><span class="popup-title">Ref [1]</span>Baars, B. J. (1988). <em>A Cognitive Theory of Consciousness</em>. Cambridge University Press. Proposes broadcasting information across a &#8220;global workspace.&#8221;<a class="popup-link" href="https://en.wikipedia.org/wiki/Global_workspace_theory" target="_blank" rel="noopener">Learn more &#8599;</a></span></span>.</strong> Bernard Baars&#8217; GWT proposes broadcasting information across a &#8220;global workspace.&#8221; This captures important aspects of attention but lacks mathematical formalization.</p>

<p><strong><span class="margin-ref">Predictive Processing<span class="margin-popup"><span class="popup-title">Ref [4, 14, 15]</span>Clark (2013), Rao &amp; Ballard (1999), Seth (2014). The most successful computational account of perception, but doesn&#8217;t distinguish conscious from unconscious prediction.<a class="popup-link" href="https://doi.org/10.1017/S0140525X12000477" target="_blank" rel="noopener">Clark, 2013 &#8599;</a></span></span>.</strong> The predictive processing framework is arguably the most successful computational account of perception, but it does not explain what distinguishes <em>conscious</em> prediction from <em>unconscious</em> prediction.</p>

<h3>The Need for a Generalized Model of Intelligence</h3>

<p>What is missing is a unified account that explains three things simultaneously:</p>

<ul>
<li><strong>Why consciousness arises</strong>&#8202;&#8212;&#8202;the Climbing Problem.</li>
<li><strong>How consciousness works</strong>&#8202;&#8212;&#8202;the mechanisms of attention, prediction, integration, and meta-cognition.</li>
<li><strong>How to measure consciousness</strong>&#8202;&#8212;&#8202;a quantitative metric applicable to any system.</li>
</ul>

<p>Cognitive Parsimony Theory attempts to provide all three. If correct, building generally intelligent systems is not primarily a question of scale&#8202;&#8212;&#8202;it is a question of optimization objective.</p>

<!-- ═══ SECTION 2: THE MATH ═══ -->
<h2>Cognitive Parsimony Theory: Mathematics of the Parsimony Index</h2>

<h3>The Parsimony Principle and Consciousness</h3>

<p>The theory draws its name from the <em>parsimony principle</em>&#8202;&#8212;&#8202;the deep scientific intuition that nature tends toward simplicity and economy. In physics, the principle of least action governs the paths of particles. In biology, natural selection relentlessly prunes inefficiency. In statistics, Occam&#8217;s razor favors the simplest model that explains the data.</p>

<p>We propose that the same principle governs consciousness. Among all possible information-processing strategies a system could adopt, consciousness corresponds to the most <em>parsimonious</em> one: the strategy that achieves the best predictions from the least wasted effort. Consciousness, on this view, is what efficient prediction <em>looks like from the inside</em>.</p>

<h3>Core Equation</h3>

<p>We propose that conscious systems minimize the Parsimony Index ($\pi$):</p>

<div class="equation">$$\pi = \frac{F}{\text{Sn}}$$<span class="eq-label">(3)</span></div>

<p>Expanding both terms yields the complete equation:</p>

<div class="equation boxed">$$\pi = \frac{F}{\text{Sn}} = \frac{D_{KL}\!\left[q(\theta)\,\|\,p(\theta)\right] - \mathbb{E}_q\!\left[\log p(o|\theta)\right]}{\displaystyle\sum_i w_i \cdot I(s_i)}$$<span class="eq-label">(4)</span></div>

<p>The numerator decomposes into two terms: a <em>complexity</em> cost (how far the system&#8217;s internal model deviates from its prior beliefs) minus an <em>accuracy</em> term (how well the model explains the observations). The denominator captures how much relevant, well-weighted sensory information the system is processing, where $I(s_i) = -\log_2 p(s_i)$ is the <span class="margin-ref">Shannon information<span class="margin-popup"><span class="popup-title">Ref [16]</span>Shannon, C. E. (1948). A mathematical theory of communication. <em>Bell System Technical Journal</em>, 27(3), 379&#8211;423. The foundational work defining information content as the negative log of probability.<a class="popup-link" href="https://doi.org/10.1002/j.1538-7305.1948.tb01338.x" target="_blank" rel="noopener">View paper &#8599;</a></span></span> content of sensation $i$.</p>

<h3>Why a Ratio, Not a Sum</h3>

<p>The choice of division is not arbitrary&#8202;&#8212;&#8202;it is the only operation that captures efficiency:</p>

<div class="equation">$$\text{Addition: } F + \text{Sn} = 101 \quad\text{for both } (F{=}1, \text{Sn}{=}100) \text{ and } (F{=}100, \text{Sn}{=}1)$$$$\text{Division: } F / \text{Sn} = 0.01 \quad\text{for } (F{=}1, \text{Sn}{=}100); \quad = 100 \quad\text{for } (F{=}100, \text{Sn}{=}1)$$<span class="eq-label">(5&#8211;6)</span></div>

<p>Just as fuel economy is miles per gallon, cognitive parsimony is accuracy per information.</p>

<h3>Free Energy ($F$): The Numerator</h3>

<p>Free energy, from the Free Energy Principle, decomposes into two competing terms:</p>

<div class="equation">$$F = \underbrace{D_{KL}\!\left[q(\theta)\,\|\,p(\theta)\right]}_{\text{complexity}} - \underbrace{\mathbb{E}_q\!\left[\log p(o|\theta)\right]}_{\text{accuracy}}$$<span class="eq-label">(7)</span></div>

<p>The first term penalizes model complexity&#8202;&#8212;&#8202;how far the system&#8217;s approximate posterior $q(\theta)$ deviates from its prior $p(\theta)$. The second term rewards accuracy. Under Gaussian assumptions, the accuracy term reduces to precision-weighted squared prediction errors:</p>

<div class="equation">$$F \approx \sum_j \frac{(o_j - \hat{o}_j)^2}{2\sigma_j^2} + \text{complexity terms}$$<span class="eq-label">(8)</span></div>

<p>This form makes the intuition concrete: $F$ measures how wrong the system&#8217;s predictions were, weighted by how confident it was. This is the form used in <span class="margin-ref">predictive coding<span class="margin-popup"><span class="popup-title">Ref [14]</span>Rao, R. P. N. &amp; Ballard, D. H. (1999). Predictive coding in the visual cortex. <em>Nature Neuroscience</em>, 2, 79&#8211;87. Each cortical level generates top-down predictions; bottom-up signals carry precision-weighted errors.<a class="popup-link" href="https://doi.org/10.1038/4580" target="_blank" rel="noopener">View paper &#8599;</a></span></span> models of the brain.</p>

<p>What Cognitive Parsimony Theory adds is the denominator.</p>

<p>A critical question is where the prior $p(\theta)$ comes from. In our framework, the prior is defined by memory. At the shortest timescale, $p(\theta)$ at time $t$ is simply the posterior $q(\theta)$ from time $t{-}1$. Over longer timescales, $p(\theta)$ reflects accumulated experience&#8202;&#8212;&#8202;a compressed world model. Without memory, $p(\theta)$ would reset to an uninformative default at every step, $F$ could never systematically decrease, and $\pi$ minimization would be impossible.</p>

<h3>Sensory Information ($\text{Sn}$): The Denominator</h3>

<p>$\text{Sn}$ is the novel component:</p>

<div class="equation">$$\text{Sn} = \sum_i w_i \cdot I(s_i) = -\sum_i w_i \cdot \log_2 p(s_i)$$<span class="eq-label">(9)</span></div>

<p>where $I(s_i)$ is the Shannon information content of sensation $i$, and $w_i$ is a learned salience weight. $\text{Sn}$ is not raw data volume&#8202;&#8212;&#8202;it is <em>relevant, well-weighted</em> information. The salience weights are learned through experience, creating a virtuous cycle: better weights &#8594; higher $\text{Sn}$ &#8594; lower $\pi$ &#8594; further improvement.</p>

<h3>The Climbing Problem: Why Minimizing $\pi$ Creates Ascent</h3>

<!-- Figure 1: Climbing Problem - SVG recreation -->
<div class="figure-container">
<svg viewBox="0 0 660 280" xmlns="http://www.w3.org/2000/svg">
  <defs>
    <marker id="arrow1" markerWidth="8" markerHeight="8" refX="6" refY="4" orient="auto"><path d="M0,0 L8,4 L0,8" fill="#e5e1d8"/></marker>
    <marker id="arrow-gold" markerWidth="8" markerHeight="8" refX="6" refY="4" orient="auto"><path d="M0,0 L8,4 L0,8" fill="#F1B82F"/></marker>
    <marker id="arrow-gray" markerWidth="8" markerHeight="8" refX="6" refY="4" orient="auto"><path d="M0,0 L8,4 L0,8" fill="#6e6b63"/></marker>
  </defs>
  <!-- Axes -->
  <line x1="50" y1="240" x2="570" y2="240" stroke="#e5e1d8" stroke-width="1.5" marker-end="url(#arrow1)"/>
  <line x1="50" y1="240" x2="50" y2="20" stroke="#e5e1d8" stroke-width="1.5" marker-end="url(#arrow1)"/>
  <text x="310" y="270" fill="#6e6b63" font-size="12" font-family="Manrope" text-anchor="middle">Time</text>
  <text x="18" y="130" fill="#6e6b63" font-size="11" font-family="Manrope" transform="rotate(-90,18,130)" text-anchor="middle">Complexity of Information Processing</text>
  <!-- FEP line -->
  <line x1="70" y1="190" x2="540" y2="190" stroke="#6e6b63" stroke-width="1.5" stroke-dasharray="8,6"/>
  <text x="548" y="194" fill="#6e6b63" font-size="11" font-family="Manrope">FEP only</text>
  <text x="280" y="182" fill="#6e6b63" font-size="10" font-family="Manrope" text-anchor="middle" font-style="italic">Thermostat: maintains homeostasis</text>
  <!-- Pi minimization curve -->
  <path d="M70,190 C140,170 200,130 260,100 C320,72 400,50 520,32" stroke="#F1B82F" stroke-width="3" fill="none"/>
  <text x="520" y="26" fill="#F1B82F" font-size="12" font-family="Manrope" font-weight="700">&#960; minimization</text>
  <!-- Path 2 arrow -->
  <line x1="180" y1="120" x2="180" y2="60" stroke="#F1B82F" stroke-width="1.2" marker-end="url(#arrow-gold)"/>
  <text x="190" y="52" fill="#F1B82F" font-size="10" font-family="Manrope">Path 2: Increase Sn</text>
  <text x="190" y="66" fill="#F1B82F" font-size="10" font-family="Manrope" font-style="italic">(seek richer experience)</text>
  <!-- Path 1 arrow -->
  <line x1="130" y1="195" x2="130" y2="225" stroke="#6e6b63" stroke-width="1.2" marker-end="url(#arrow-gray)"/>
  <text x="140" y="235" fill="#6e6b63" font-size="10" font-family="Manrope">Path 1 only: Reduce F</text>
</svg>
<div class="figure-caption"><strong>Figure 1: The Climbing Problem.</strong> FEP ($F$ minimization alone) leads to homeostasis. Minimizing $\pi = F/\text{Sn}$ creates upward pressure: once $F$ is low, further reduction requires increasing $\text{Sn}$, driving richer information processing.</div>
</div>

<p>Under FEP alone, a system can minimize $F$ by becoming very simple. Minimizing $\pi$ provides two pathways:</p>

<p><strong>Path 1: Reduce $F$.</strong> Build better models. This alone is homeostatic.</p>

<p><strong>Path 2: Increase $\text{Sn}$.</strong> Seek richer, more informative experience. Learn better salience weights. This drives ascent.</p>

<p>Path 2 is the key. Once $F$ is low, the only way to further reduce $\pi$ is to increase $\text{Sn}$&#8202;&#8212;&#8202;to seek and learn from more informative experiences. This is why conscious beings are curious. Curiosity is the behavioral signature of $\text{Sn}$ maximization.</p>

<h3>Regularized $\pi$ for Stability</h3>

<p>When both $F$ and $\text{Sn}$ approach zero, the ratio becomes unstable. We introduce regularization:</p>

<div class="equation">$$\pi = \frac{F + \varepsilon}{\text{Sn} + \varepsilon}$$<span class="eq-label">(10)</span></div>

<p>where $\varepsilon$ is a small constant ($\approx 0.1$) representing baseline metabolic cost&#8202;&#8212;&#8202;analogous to Laplace smoothing in probability theory.</p>

<!-- ═══ SECTION 3: COGNITIVE SCIENCE ═══ -->
<h2>A Cognitive Science Perspective</h2>

<h3>Differentiating Experience from Processing</h3>

<p>Most existing theories describe features of conscious processing&#8202;&#8212;&#8202;they tell us how consciousness works once it exists, not why it arises. Cognitive Parsimony Theory shifts the question: consciousness is not a feature some systems happen to have, but an <em>optimization solution</em>. Systems under pressure to efficiently process continuous experience develop consciousness as the parsimonious strategy.</p>

<h3>The Climbing Problem: How Consciousness Arises</h3>

<p>We distinguish two problems:</p>

<p><strong>The Mechanism Problem:</strong> How does consciousness work? (Domain of most theories.)</p>

<p><strong>The Climbing Problem:</strong> How does consciousness <em>arise</em>? What transforms an unconscious system into a conscious one?</p>

<p>CPT answers the Climbing Problem. Under $\pi$ minimization, a system must simultaneously reduce prediction errors <em>and</em> increase information quality. The denominator creates a ratchet: once efficient, the only way forward is richer information.</p>

<h3>Biological Parallels</h3>

<p><strong>Attention as learned salience.</strong> Organisms learn to prioritize relevant information&#8202;&#8212;&#8202;precisely what $\text{Sn}$&#8217;s salience weights capture.</p>

<p><strong>Curiosity.</strong> Organisms actively seek informative experiences&#8202;&#8212;&#8202;the behavioral signature of $\text{Sn}$ maximization.</p>

<p><strong>Predictive coding.</strong> Hierarchical prediction errors map onto $F$; precision-weighting is equivalent to salience weights in $\text{Sn}$.</p>

<p><strong><span class="margin-ref">Flow states<span class="margin-popup"><span class="popup-title">Ref [5]</span>Csikszentmihalyi, M. (1990). <em>Flow: The Psychology of Optimal Experience</em>. Harper &amp; Row. The state of complete absorption in an activity&#8202;&#8212;&#8202;corresponds to very low &#960;.<a class="popup-link" href="https://en.wikipedia.org/wiki/Flow_(psychology)" target="_blank" rel="noopener">Learn more &#8599;</a></span></span>.</strong> Csikszentmihalyi&#8217;s &#8220;flow&#8221; corresponds to very low $\pi$: high $\text{Sn}$, low $F$.</p>

<!-- ═══ SECTION 4: STATE SPACE ═══ -->
<h2>The $F$/$\text{Sn}$ State Space: A Map of Consciousness</h2>

<h3>The Four Quadrants</h3>

<!-- Figure 2: State Space - SVG with labeled axes -->
<div class="figure-container">
<svg viewBox="0 0 560 400" xmlns="http://www.w3.org/2000/svg">
  <defs>
    <marker id="ax2" markerWidth="8" markerHeight="8" refX="6" refY="4" orient="auto"><path d="M0,0 L8,4 L0,8" fill="#e5e1d8"/></marker>
  </defs>
  <!-- Quadrant fills -->
  <rect x="60" y="10" width="230" height="170" rx="4" fill="rgba(255,100,100,0.06)"/>
  <rect x="300" y="10" width="230" height="170" rx="4" fill="rgba(241,184,47,0.05)"/>
  <rect x="60" y="190" width="230" height="170" rx="4" fill="rgba(255,255,255,0.025)"/>
  <rect x="300" y="190" width="230" height="170" rx="4" fill="rgba(241,184,47,0.09)"/>
  <!-- Divider lines -->
  <line x1="295" y1="10" x2="295" y2="360" stroke="rgba(255,255,255,0.08)" stroke-width="1"/>
  <line x1="60" y1="185" x2="530" y2="185" stroke="rgba(255,255,255,0.08)" stroke-width="1"/>
  <!-- DIZZY (top-left) -->
  <text x="175" y="55" fill="#cc6666" font-size="16" font-family="Manrope" text-anchor="middle" font-weight="700">DIZZY</text>
  <text x="175" y="78" fill="#cc6666" font-size="11" font-family="Manrope" text-anchor="middle" font-style="italic">&#960; = High/Low = Very High</text>
  <text x="175" y="105" fill="#8a6060" font-size="10" font-family="Manrope" text-anchor="middle">Disoriented. High prediction</text>
  <text x="175" y="120" fill="#8a6060" font-size="10" font-family="Manrope" text-anchor="middle">error, no useful data.</text>
  <text x="175" y="145" fill="#8a6060" font-size="10" font-family="Manrope" text-anchor="middle">Kierkegaardian vertigo.</text>
  <text x="175" y="160" fill="#8a6060" font-size="10" font-family="Manrope" text-anchor="middle">A trap state.</text>
  <!-- LEARNING (top-right) -->
  <text x="415" y="55" fill="#c9a62c" font-size="16" font-family="Manrope" text-anchor="middle" font-weight="700">LEARNING</text>
  <text x="415" y="78" fill="#c9a62c" font-size="11" font-family="Manrope" text-anchor="middle" font-style="italic">&#960; = High/High = Moderate</text>
  <text x="415" y="105" fill="#8a8040" font-size="10" font-family="Manrope" text-anchor="middle">Confused but engaged.</text>
  <text x="415" y="120" fill="#8a8040" font-size="10" font-family="Manrope" text-anchor="middle">Rich data, poor models.</text>
  <text x="415" y="145" fill="#8a8040" font-size="10" font-family="Manrope" text-anchor="middle">Strong learning pressure.</text>
  <text x="415" y="160" fill="#8a8040" font-size="10" font-family="Manrope" text-anchor="middle">This is where growth happens.</text>
  <!-- AMBIGUOUS (bottom-left) -->
  <text x="175" y="235" fill="#8a8880" font-size="16" font-family="Manrope" text-anchor="middle" font-weight="700">REST</text>
  <text x="175" y="258" fill="#8a8880" font-size="11" font-family="Manrope" text-anchor="middle" font-style="italic">&#960; = Low/Low = Indeterminate</text>
  <text x="175" y="285" fill="#6a6860" font-size="10" font-family="Manrope" text-anchor="middle">Sleep or meditation?</text>
  <text x="175" y="300" fill="#6a6860" font-size="10" font-family="Manrope" text-anchor="middle">Both F and Sn are low.</text>
  <text x="175" y="325" fill="#6a6860" font-size="10" font-family="Manrope" text-anchor="middle">Requires &#966; and C to</text>
  <text x="175" y="340" fill="#6a6860" font-size="10" font-family="Manrope" text-anchor="middle">distinguish sub-states.</text>
  <!-- OPTIMAL (bottom-right) -->
  <text x="415" y="228" fill="#F1B82F" font-size="16" font-family="Manrope" text-anchor="middle" font-weight="700">OPTIMAL</text>
  <text x="415" y="248" fill="#F1B82F" font-size="12" font-family="Manrope" text-anchor="middle">(Flow)</text>
  <text x="415" y="271" fill="#c9a62c" font-size="11" font-family="Manrope" text-anchor="middle" font-style="italic">&#960; = Low/High = Very Low</text>
  <text x="415" y="298" fill="#a89040" font-size="10" font-family="Manrope" text-anchor="middle">Peak consciousness.</text>
  <text x="415" y="313" fill="#a89040" font-size="10" font-family="Manrope" text-anchor="middle">Accurate predictions,</text>
  <text x="415" y="328" fill="#a89040" font-size="10" font-family="Manrope" text-anchor="middle">rich information.</text>
  <text x="415" y="348" fill="#a89040" font-size="10" font-family="Manrope" text-anchor="middle">Effortless mastery.</text>
  <!-- Axes -->
  <line x1="55" y1="365" x2="540" y2="365" stroke="#e5e1d8" stroke-width="1.5" marker-end="url(#ax2)"/>
  <line x1="55" y1="365" x2="55" y2="5" stroke="#e5e1d8" stroke-width="1.5" marker-end="url(#ax2)"/>
  <!-- Axis labels -->
  <text x="295" y="393" fill="#6e6b63" font-size="12" font-family="Manrope" text-anchor="middle" font-weight="600">Sn (Sensory Information)</text>
  <text x="20" y="185" fill="#6e6b63" font-size="12" font-family="Manrope" text-anchor="middle" font-weight="600" transform="rotate(-90,20,185)">F (Prediction Error)</text>
  <!-- Axis ticks -->
  <text x="175" y="382" fill="#6e6b63" font-size="10" font-family="Manrope" text-anchor="middle">Low</text>
  <text x="415" y="382" fill="#6e6b63" font-size="10" font-family="Manrope" text-anchor="middle">High</text>
  <text x="45" y="280" fill="#6e6b63" font-size="10" font-family="Manrope" text-anchor="end">Low</text>
  <text x="45" y="95" fill="#6e6b63" font-size="10" font-family="Manrope" text-anchor="end">High</text>
</svg>
<div class="figure-caption"><strong>Figure 2: The $F$/$\text{Sn}$ state space.</strong> Each quadrant represents a qualitatively different mode of information processing. $F$ (prediction error) increases along the vertical axis; $\text{Sn}$ (sensory information) increases along the horizontal axis. The Optimal quadrant (bottom-right) is the target of $\pi$ minimization.</div>
</div>

<h3>Quadrant Analysis</h3>

<h4>Optimal State (Low $F$, High $\text{Sn}$)</h4>
<p>The target: rich sensory information with minimal prediction error. In human experience: flow, expert performance, heightened awareness. $\pi$ is very low; consciousness is vivid.</p>

<h4>Learning State (High $F$, High $\text{Sn}$)</h4>
<p>Rich information but the world model is failing. A first day at a new job. $\pi$ is moderate. Strong learning pressure&#8202;&#8212;&#8202;the system has the information it needs but hasn&#8217;t built the right models yet.</p>

<h4>Dizzy State (High $F$, Low $\text{Sn}$)</h4>
<p>Confused with no informative data to learn from. <span class="margin-ref">Kierkegaard&#8217;s<span class="margin-popup"><span class="popup-title">Ref [9]</span>Kierkegaard, S. (1844/1980). <em>The Concept of Anxiety</em>. Princeton University Press. The &#8220;dizziness of freedom&#8221;&#8202;&#8212;&#8202;vertigo arising from confronting infinite possibility with insufficient grounding.<a class="popup-link" href="https://en.wikipedia.org/wiki/The_Concept_of_Anxiety" target="_blank" rel="noopener">Learn more &#8599;</a></span></span> vertigo of possibility. $\pi$ is very high. A trap state requiring environmental intervention to escape.</p>

<h4>Rest State (Low $F$, Low $\text{Sn}$)</h4>
<p>Contains deep sleep (unconscious), meditation (conscious), and hypnosis (partial). All share low $F$ and low $\text{Sn}$ but differ profoundly. This reveals $\pi$ alone is not sufficient&#8202;&#8212;&#8202;we need $\varphi$ and $C_{\text{capacity}}$.</p>

<h3>State Trajectories</h3>

<!-- Figure 3: State Trajectories - SVG -->
<div class="figure-container">
<svg viewBox="0 0 500 300" xmlns="http://www.w3.org/2000/svg">
  <defs>
    <marker id="arr-t" markerWidth="8" markerHeight="8" refX="6" refY="4" orient="auto"><path d="M0,0 L8,4 L0,8" fill="#e5e1d8"/></marker>
  </defs>
  <!-- Quadrant backgrounds -->
  <rect x="50" y="10" width="200" height="120" fill="rgba(255,100,100,0.06)" rx="4"/>
  <rect x="260" y="10" width="200" height="120" fill="rgba(241,184,47,0.06)" rx="4"/>
  <rect x="50" y="140" width="200" height="120" fill="rgba(255,255,255,0.03)" rx="4"/>
  <rect x="260" y="140" width="200" height="120" fill="rgba(241,184,47,0.08)" rx="4"/>
  <!-- Labels -->
  <text x="150" y="126" fill="#6e6b63" font-size="10" font-family="Manrope" text-anchor="middle" opacity="0.6">DIZZY</text>
  <text x="360" y="126" fill="#6e6b63" font-size="10" font-family="Manrope" text-anchor="middle" opacity="0.6">LEARNING</text>
  <text x="150" y="256" fill="#6e6b63" font-size="10" font-family="Manrope" text-anchor="middle" opacity="0.6">REST</text>
  <text x="360" y="256" fill="#6e6b63" font-size="10" font-family="Manrope" text-anchor="middle" opacity="0.6">OPTIMAL</text>
  <!-- Trajectory -->
  <path d="M370,40 C370,80 390,140 380,170 C370,200 330,220 280,210 C230,200 180,210 140,215" stroke="#F1B82F" stroke-width="2.5" fill="none" stroke-linecap="round"/>
  <circle cx="370" cy="40" r="5" fill="#F1B82F"/>
  <circle cx="140" cy="215" r="4" fill="#F1B82F" opacity="0.6"/>
  <!-- Annotations -->
  <text x="385" y="35" fill="#F1B82F" font-size="10" font-family="Manrope">t&#8320;: Novel situation</text>
  <text x="400" y="155" fill="#F1B82F" font-size="10" font-family="Manrope">t&#8321;: Models improve</text>
  <text x="290" y="235" fill="#F1B82F" font-size="10" font-family="Manrope">t&#8322;: Mastery</text>
  <text x="75" y="235" fill="#F1B82F" font-size="10" font-family="Manrope" opacity="0.7">t&#8323;: Rest</text>
  <!-- Axes -->
  <line x1="48" y1="265" x2="465" y2="265" stroke="#e5e1d8" stroke-width="1" marker-end="url(#arr-t)"/>
  <line x1="48" y1="265" x2="48" y2="5" stroke="#e5e1d8" stroke-width="1" marker-end="url(#arr-t)"/>
  <text x="260" y="285" fill="#6e6b63" font-size="11" font-family="Manrope" text-anchor="middle">Sn (low &#8594; high)</text>
  <text x="16" y="140" fill="#6e6b63" font-size="11" font-family="Manrope" transform="rotate(-90,16,140)" text-anchor="middle">F (low &#8594; high)</text>
</svg>
<div class="figure-caption"><strong>Figure 3: An example state trajectory.</strong> A conscious agent begins in Learning ($t_0$), descends to Optimal as models improve ($t_1 \to t_2$), then enters Rest during recovery ($t_3$). Dynamic, multi-quadrant trajectories are a hallmark of conscious processing.</div>
</div>

<!-- ═══ SECTION 5: BEYOND PI ═══ -->
<h2>Beyond $\pi$: Integration, Capacity, and the Full Framework</h2>

<p>The complete theory:</p>

<div class="equation boxed">$$\text{Consciousness} \;\propto\; \frac{1}{\pi} \times \varphi \times C_{\text{capacity}}$$<span class="eq-label">(11)</span></div>

<h3>Why $\pi$ Alone Is Not Sufficient</h3>

<p>A lookup table mapping every input to a correct output has $F \approx 0$ and low $\text{Sn}$, giving low $\pi$. But it is not conscious&#8202;&#8212;&#8202;its entries are independent (no integration) and it has no responsiveness. Low $\pi$ is necessary but not sufficient.</p>

<h3>Integration ($\varphi$)</h3>

<p>Borrowed from <span class="margin-ref">IIT<span class="margin-popup"><span class="popup-title">Ref [17]</span>Tononi, G. (2004). An information integration theory of consciousness. <em>BMC Neuroscience</em>, 5, 42. &#966; measures how much the whole exceeds the sum of its parts.<a class="popup-link" href="https://doi.org/10.1186/1471-2202-5-42" target="_blank" rel="noopener">View paper &#8599;</a></span></span>, $\varphi$ measures integrated information:</p>

<div class="equation">$$\varphi = I(\text{whole}) - \sum_i I(\text{part}_i)$$<span class="eq-label">(12)</span></div>

<p>In our theory, $\varphi$ is not the definition of consciousness but a necessary correlate. Minimizing $\pi$ drives $\varphi$ upward because integration improves prediction. $\varphi$ resolves the Rest quadrant: meditation (high $\varphi$) vs. sleep (low $\varphi$).</p>

<h3>Counterfactual Capacity ($C_{\text{capacity}}$)</h3>

<p>$C_{\text{capacity}}$ measures response repertoire richness. Inspired by the <span class="margin-ref">perturbation complexity index<span class="margin-popup"><span class="popup-title">Ref [2]</span>Casali, A. G., et al. (2013). A theoretically based index of consciousness independent of sensory processing and behavior. <em>Science Translational Medicine</em>, 5(198). TMS&#8211;EEG measure of brain complexity.<a class="popup-link" href="https://doi.org/10.1126/scitranslmed.3006294" target="_blank" rel="noopener">View paper &#8599;</a></span></span>: a conscious brain produces complex, differentiated responses to stimulation; an unconscious brain produces stereotyped waves.</p>

<!-- Figure 4: Disambiguation cards -->
<div class="disambig-grid">
  <div class="disambig-card">
    <h5 style="color:#6e6b63">Deep Sleep</h5>
    <div class="d-row">&#960;: Low</div>
    <div class="d-row">&#966;: Low</div>
    <div class="d-row">C<sub>capacity</sub>: Low</div>
    <div class="d-state" style="color:#6e6b63">Unconscious</div>
  </div>
  <div class="disambig-card" style="border-color:var(--accent)">
    <h5 style="color:var(--accent)">Meditation</h5>
    <div class="d-row">&#960;: Low</div>
    <div class="d-row">&#966;: High</div>
    <div class="d-row">C<sub>capacity</sub>: High</div>
    <div class="d-state" style="color:var(--accent)">Conscious</div>
  </div>
  <div class="disambig-card">
    <h5 style="color:#a89030">Hypnosis</h5>
    <div class="d-row">&#960;: Low</div>
    <div class="d-row">&#966;: Moderate</div>
    <div class="d-row">C<sub>capacity</sub>: Moderate</div>
    <div class="d-state" style="color:#a89030">Partially conscious</div>
  </div>
</div>
<div class="figure-caption"><strong>Figure 4: Disambiguating the Rest quadrant.</strong> Three states share similar $\pi$ values but differ in $\varphi$ and $C_{\text{capacity}}$, enabling phenomenological distinction.</div>

<h3>The Role of Memory</h3>

<p>Memory serves three functions: <strong>model improvement</strong> (accumulated experience reduces $F$), <strong>salience calibration</strong> (learned weights improve $\text{Sn}$), and <strong>temporal continuity</strong> (connecting present to past).</p>

<p>Memory defines the prior $p(\theta)$ at three timescales:</p>

<p><strong>Decision-to-decision.</strong> The prior at time $t$ is the posterior from time $t{-}1$. A rolling Bayesian update requiring only the current belief state.</p>

<p><strong>Session-level.</strong> Over minutes to hours, the prior accumulates a richer model of the current environment&#8202;&#8212;&#8202;spatial layout, obstacle positions, recurring patterns.</p>

<p><strong>Lifetime.</strong> Experience consolidates into a compressed world model&#8202;&#8212;&#8202;the equivalent of semantic memory. This is slow, distilled knowledge: fire is hot, gravity pulls down, faces have two eyes.</p>

<p>Memory shapes both sides of the $\pi$ ratio&#8202;&#8212;&#8202;the numerator (through $p(\theta)$) and the denominator (through learned salience weights). Without memory, $\pi$ minimization cannot proceed.</p>

<h3>Prat and Pren: Attention and Action</h3>

<p><strong><span class="def-term">Prat<span class="def-popup"><span class="def-symbol">Prat</span><span class="def-name">Predictive Relevance-weighted Attention</span><span class="def-desc">Determines salience weights w&#7522; in Sn. Learns which sensory inputs are most predictively useful. Controls the denominator of &#960;.</span></span></span></strong> (Predictive Relevance-weighted Attention) determines salience weights $w_i$ in $\text{Sn}$. It learns which inputs are predictively useful. <strong><span class="def-term">Pren<span class="def-popup"><span class="def-symbol">Pren</span><span class="def-name">Predictive Relevance-weighted Encoding</span><span class="def-desc">Selects actions that are predictable (low F) and informative (high Sn). Controls the numerator of &#960;.</span></span></span></strong> (Predictive Relevance-weighted Encoding) selects actions that are predictable (low $F$) and informative (high $\text{Sn}$). Together, Prat shapes the denominator and Pren shapes the numerator.</p>

<h3>Variable Summary</h3>

<div class="table-container">
<table>
<tr><th>Symbol</th><th>Name</th><th>Role in Theory</th><th>What It Captures</th></tr>
<tr><td>$\pi$</td><td>Parsimony Index</td><td>Core optimization target</td><td>Predictive efficiency ($F/\text{Sn}$)</td></tr>
<tr><td>$F$</td><td>Free Energy</td><td>Numerator of $\pi$</td><td>Prediction error + complexity</td></tr>
<tr><td>$\text{Sn}$</td><td>Sensory Information</td><td>Denominator of $\pi$</td><td>Salience-weighted Shannon info</td></tr>
<tr><td>$\varphi$</td><td>Integration</td><td>Consciousness correlate</td><td>Information binding</td></tr>
<tr><td>$C_{\text{cap}}$</td><td>Counterfactual Capacity</td><td>Consciousness correlate</td><td>Response repertoire richness</td></tr>
<tr><td>Prat</td><td>Pred. Relevance Attention</td><td>Controls $\text{Sn}$</td><td>Learned salience weights</td></tr>
<tr><td>Pren</td><td>Pred. Relevance Encoding</td><td>Controls $F$</td><td>Learned action selection</td></tr>
</table>
<div class="table-caption"><strong>Table 1:</strong> Complete variable summary for Cognitive Parsimony Theory.</div>
</div>

<h3>How the Variables Connect: A Unified Picture</h3>

<!-- Figure 5: Variable Relationship Map - SVG -->
<div class="figure-container">
<svg viewBox="0 0 500 380" xmlns="http://www.w3.org/2000/svg">
  <defs>
    <marker id="a-b" markerWidth="8" markerHeight="8" refX="6" refY="4" orient="auto"><path d="M0,0 L8,4 L0,8" fill="#F1B82F"/></marker>
    <marker id="a-g" markerWidth="8" markerHeight="8" refX="6" refY="4" orient="auto"><path d="M0,0 L8,4 L0,8" fill="#6e6b63"/></marker>
    <marker id="a-r" markerWidth="8" markerHeight="8" refX="6" refY="4" orient="auto"><path d="M0,0 L8,4 L0,8" fill="#cc6666"/></marker>
    <marker id="a-grn" markerWidth="8" markerHeight="8" refX="6" refY="4" orient="auto"><path d="M0,0 L8,4 L0,8" fill="#7cb87c"/></marker>
  </defs>
  <!-- Memory -->
  <rect x="200" y="10" width="100" height="36" rx="8" fill="rgba(255,255,255,0.05)" stroke="#6e6b63"/>
  <text x="250" y="33" fill="#6e6b63" font-size="12" font-family="Manrope" text-anchor="middle" font-weight="500">Memory</text>
  <!-- Prat and Pren -->
  <rect x="70" y="80" width="90" height="36" rx="8" fill="rgba(241,184,47,0.08)" stroke="rgba(241,184,47,0.3)"/>
  <text x="115" y="103" fill="#F1B82F" font-size="12" font-family="Manrope" text-anchor="middle" font-weight="600">Prat</text>
  <rect x="340" y="80" width="90" height="36" rx="8" fill="rgba(241,184,47,0.08)" stroke="rgba(241,184,47,0.3)"/>
  <text x="385" y="103" fill="#F1B82F" font-size="12" font-family="Manrope" text-anchor="middle" font-weight="600">Pren</text>
  <!-- Sn and F -->
  <rect x="70" y="160" width="90" height="36" rx="8" fill="rgba(241,184,47,0.12)" stroke="#F1B82F"/>
  <text x="115" y="183" fill="#F1B82F" font-size="13" font-family="Playfair Display" text-anchor="middle" font-weight="700">Sn</text>
  <rect x="340" y="160" width="90" height="36" rx="8" fill="rgba(241,184,47,0.12)" stroke="#F1B82F"/>
  <text x="385" y="183" fill="#F1B82F" font-size="13" font-family="Playfair Display" text-anchor="middle" font-weight="700">F</text>
  <!-- Pi -->
  <rect x="195" y="160" width="110" height="36" rx="8" fill="rgba(241,184,47,0.15)" stroke="#F1B82F" stroke-width="1.5"/>
  <text x="250" y="183" fill="#F1B82F" font-size="14" font-family="Playfair Display" text-anchor="middle" font-weight="700">&#960; = F/Sn</text>
  <!-- Phi and Ccap -->
  <rect x="100" y="260" width="90" height="36" rx="8" fill="rgba(100,200,130,0.08)" stroke="rgba(100,200,130,0.3)"/>
  <text x="145" y="283" fill="#7cb87c" font-size="12" font-family="Playfair Display" text-anchor="middle" font-style="italic">&#966;</text>
  <rect x="310" y="260" width="90" height="36" rx="8" fill="rgba(100,200,130,0.08)" stroke="rgba(100,200,130,0.3)"/>
  <text x="355" y="283" fill="#7cb87c" font-size="11" font-family="Manrope" text-anchor="middle">C<tspan font-size="9" dy="2">cap</tspan></text>
  <!-- Consciousness -->
  <rect x="185" y="335" width="130" height="36" rx="8" fill="rgba(255,255,255,0.05)" stroke="#6e6b63"/>
  <text x="250" y="358" fill="#e5e1d8" font-size="12" font-family="Manrope" text-anchor="middle" font-weight="700">Consciousness</text>
  <!-- Arrows: Prat -> Sn -->
  <line x1="115" y1="116" x2="115" y2="156" stroke="#F1B82F" stroke-width="1.2" marker-end="url(#a-b)"/>
  <text x="108" y="140" fill="#F1B82F" font-size="9" font-family="Manrope" text-anchor="end">weights</text>
  <!-- Pren -> F -->
  <line x1="385" y1="116" x2="385" y2="156" stroke="#F1B82F" stroke-width="1.2" marker-end="url(#a-b)"/>
  <text x="393" y="140" fill="#F1B82F" font-size="9" font-family="Manrope">actions</text>
  <!-- Sn -> Pi -->
  <line x1="164" y1="178" x2="191" y2="178" stroke="#F1B82F" stroke-width="1.2" marker-end="url(#a-b)"/>
  <!-- F -> Pi -->
  <line x1="336" y1="178" x2="309" y2="178" stroke="#F1B82F" stroke-width="1.2" marker-end="url(#a-b)"/>
  <!-- Pi -> Phi, Ccap (dashed) -->
  <line x1="225" y1="200" x2="160" y2="256" stroke="#6e6b63" stroke-width="1" stroke-dasharray="4,4" marker-end="url(#a-g)"/>
  <line x1="275" y1="200" x2="340" y2="256" stroke="#6e6b63" stroke-width="1" stroke-dasharray="4,4" marker-end="url(#a-g)"/>
  <!-- Pi feedback to Prat/Pren (red) -->
  <path d="M210,165 C170,140 140,125 138,120" stroke="#cc6666" stroke-width="1.2" fill="none" stroke-dasharray="4,3" marker-end="url(#a-r)"/>
  <path d="M290,165 C330,140 360,125 362,120" stroke="#cc6666" stroke-width="1.2" fill="none" stroke-dasharray="4,3" marker-end="url(#a-r)"/>
  <text x="165" y="133" fill="#cc6666" font-size="8" font-family="Manrope">optimize</text>
  <text x="315" y="133" fill="#cc6666" font-size="8" font-family="Manrope">optimize</text>
  <!-- Phi/Ccap -> Consciousness -->
  <line x1="155" y1="300" x2="220" y2="332" stroke="#7cb87c" stroke-width="1" marker-end="url(#a-grn)"/>
  <line x1="345" y1="300" x2="280" y2="332" stroke="#7cb87c" stroke-width="1" marker-end="url(#a-grn)"/>
  <!-- Pi -> Consciousness -->
  <line x1="250" y1="200" x2="250" y2="331" stroke="#F1B82F" stroke-width="1.2" marker-end="url(#a-b)"/>
  <text x="260" y="270" fill="#F1B82F" font-size="9" font-family="Manrope">1/&#960;</text>
  <!-- Memory dashed -->
  <line x1="210" y1="46" x2="140" y2="76" stroke="#6e6b63" stroke-width="1" stroke-dasharray="4,4" marker-end="url(#a-g)"/>
  <line x1="290" y1="46" x2="360" y2="76" stroke="#6e6b63" stroke-width="1" stroke-dasharray="4,4" marker-end="url(#a-g)"/>
  <line x1="250" y1="46" x2="250" y2="156" stroke="#6e6b63" stroke-width="1" stroke-dasharray="4,4" marker-end="url(#a-g)"/>
  <text x="264" y="75" fill="#6e6b63" font-size="8" font-family="Manrope">prior p(&#952;)</text>
</svg>
<div class="figure-caption"><strong>Figure 5: Variable relationship map.</strong> Solid arrows show direct causal relationships; dashed arrows show emergent or supportive relationships. Red dashed arrows show the optimization feedback loop. Memory shapes the prior $p(\theta)$ in $F$ and provides the learned weights used by Prat and Pren.</div>
</div>

<p>In plain English: Prat determines what the system attends to, setting $\text{Sn}$. Pren determines what actions it takes, affecting $F$. Together they determine $\pi$. The system adjusts both to minimize $\pi$&#8202;&#8212;&#8202;closing the loop. As $\pi$ decreases, integration ($\varphi$) and responsiveness ($C_{\text{capacity}}$) increase as side effects.</p>

<!-- ═══ SECTION 6: ARCHITECTURE ═══ -->
<h2>Architecture: The Attend&#8211;Predict&#8211;Act&#8211;Learn Loop</h2>

<p>CPT is not tied to any particular neural network or hardware platform. The theory specifies <em>what</em> must be computed (and <em>why</em>), but leaves open <em>how</em> each component is realized.</p>

<h3>The Decision Cycle</h3>

<!-- Figure 6: Decision Cycle - HTML cards -->
<div class="cycle-grid">
  <div class="cycle-card c-attend">
    <h5 style="color:#F1B82F">1. Attend</h5>
    <p>Prat selects sensations. From millions of raw data points, a tractable subset is selected based on learned salience weights.</p>
    <div class="cycle-arrow">&#8594; S<sub>attended</sub></div>
  </div>
  <div class="cycle-card c-predict">
    <h5 style="color:#6496ff">2. Predict</h5>
    <p>World model generates a prediction of what attended sensations will look like after the next action.</p>
    <div class="cycle-arrow" style="color:#6496ff">&#8594; &#244;<sub>t+1</sub></div>
  </div>
  <div class="cycle-card c-act">
    <h5 style="color:#64c882">3. Act</h5>
    <p>Pren evaluates candidate actions by imagining consequences. The action minimizing expected &#960; is selected.</p>
    <div class="cycle-arrow" style="color:#64c882">&#8594; a<sub>t</sub>, o<sub>t+1</sub></div>
  </div>
  <div class="cycle-card c-learn">
    <h5 style="color:#cc7878">4. Learn</h5>
    <p>Prediction error drives updates to: world model parameters, salience weights in Prat, and memory consolidation.</p>
    <div class="cycle-arrow" style="color:#cc7878">&#8594; updated p(&#952;)</div>
  </div>
</div>
<div class="figure-caption"><strong>Figure 6: The CPT decision cycle.</strong> Each iteration: Prat selects sensory channels, the world model predicts, Pren selects an action minimizing expected $\pi$, and prediction error drives learning. The cycle repeats at 1&#8211;10 Hz.</div>

<h3>The World Model</h3>

<p>The world model is the system&#8217;s internal representation of how the environment works. CPT does not prescribe a specific architecture. The theory is compatible with:</p>

<ul>
<li><strong>Linear models</strong> (e.g. Recursive Least Squares): fast, interpretable, suitable for low-dimensional state spaces.</li>
<li><strong>Recurrent State-Space Models</strong> (e.g. Dreamer&#8217;s RSSM): learn a compressed latent space, predict in latent coordinates.</li>
<li><strong>Joint Embedding Predictive Architectures</strong> (e.g. JEPA): predict in representation space without pixel-level reconstruction.</li>
<li><strong>Transformers</strong>: long-range temporal dependencies via self-attention over past states.</li>
</ul>

<p>What matters is not the architecture but the <em>objective</em>: the world model must minimize $F$, which means minimizing prediction error while keeping the model parsimonious.</p>

<h3>State Representation</h3>

<p>A CPT agent represents the world as a state vector $\mathbf{s}_t$ constructed from sensor readings at time $t$:</p>

<div class="equation">$$\mathbf{s}_t = [\text{LiDAR}_t,\; \text{IMU}_t,\; \text{Camera}_t,\; \text{Encoders}_t,\; \dots]$$</div>

<p>The system has no privileged access to &#8220;what things are.&#8221; It receives only numerical readings&#8202;&#8212;&#8202;distances, accelerations, pixel intensities. All semantic content must be <em>discovered</em> through the relational structure of these readings over time. Reality, from the agent&#8217;s perspective, is relational.</p>

<h3>Memory Architecture</h3>

<p><strong>Working memory</strong> holds the current attended sensations&#8202;&#8212;&#8202;the contents of &#8220;consciousness&#8221; at this moment. It is small (roughly 4&#8211;7 items), transient, and directly determined by Prat&#8217;s selections.</p>

<p><strong>Episodic memory</strong> stores specific experiences as (state, action, outcome, surprise) tuples. Storage priority is gated by the product of surprise ($\pi$), attention (Prat weight), and deliberateness (Pren weight).</p>

<p><strong>Semantic memory</strong> consolidates regularities from many episodes into the world model&#8217;s learned parameters. Over time, individual episodes become generalized knowledge. This is the long-timescale memory that defines $p(\theta)$.</p>

<h3>Architecture Agnosticism</h3>

<p>A key feature of CPT is that it separates the <em>theory of consciousness</em> from the <em>engineering of prediction</em>. The theory says: minimize $\pi = F / \text{Sn}$, and consciousness-correlated properties ($\varphi$, $C_{\text{capacity}}$) will emerge. This means CPT can be tested across radically different architectures&#8202;&#8212;&#8202;a linear model on a Raspberry Pi, an RSSM on a GPU, or a transformer on a cloud server&#8202;&#8212;&#8202;and the predictions remain the same.</p>

<!-- ═══ SECTION 7: MEASURING CONSCIOUSNESS ═══ -->
<h2>Measuring Consciousness: The Consciousness Quotient</h2>

<h3>The Insight Hypothesis</h3>

<p>If consciousness arises from efficient information processing (low $\pi$), then conscious systems should demonstrate <em>disproportionate efficiency</em> on problems requiring genuine understanding. We call this the Insight Hypothesis.</p>

<h3>The Consciousness Quotient</h3>

<div class="equation">$$\text{CQ} = \frac{\text{Performance}}{\text{Training}} \times \text{Difficulty} \times \text{Novelty}$$<span class="eq-label">(13)</span></div>

<div class="table-container">
<table class="cq-table">
<tr><th>CQ Range</th><th>Interpretation</th><th>Example</th></tr>
<tr><td>&lt; 1</td><td>Unconscious; linear scaling with training</td><td>Lookup table</td></tr>
<tr><td>1&#8211;10</td><td>Uncertain; could be efficient unconscious</td><td>Well-trained network</td></tr>
<tr><td>&gt; 10</td><td>Likely conscious; disproportionate efficiency</td><td>Transfer learning</td></tr>
<tr><td>&gt; 100</td><td>Almost certainly conscious; insight-level</td><td>Discovering formulas from sparse data</td></tr>
</table>
<div class="table-caption"><strong>Table 2:</strong> Consciousness Quotient thresholds.</div>
</div>

<h3>Ramanujan-Style Problem Solving as Consciousness Probe</h3>

<!-- Figure 7: Ramanujan Levels -->
<div class="ram-levels">
  <div class="ram-level">
    <div><div class="ram-title">Level 1: Sequence Completion</div><div class="ram-desc">Derive $n(n+1)(2n+1)/6$ from 4 examples</div></div>
    <div class="ram-cq">CQ &#8776; 25</div>
  </div>
  <div class="ram-level">
    <div><div class="ram-title">Level 2: Formula Discovery</div><div class="ram-desc">Find partition function patterns from 7 examples</div></div>
    <div class="ram-cq">CQ &#8776; 40</div>
  </div>
  <div class="ram-level">
    <div><div class="ram-title">Level 3: Meta-Mathematical Insight</div><div class="ram-desc">Recognize that $3.14159\ldots$ is computable but unpatterned</div></div>
    <div class="ram-cq">CQ &#8776; 50</div>
  </div>
  <div class="ram-level">
    <div><div class="ram-title">Level 4: Creative Generalization</div><div class="ram-desc">Derive binomial theorem from $(a+b)^2$ alone</div></div>
    <div class="ram-cq">CQ &#8776; 60</div>
  </div>
</div>
<div class="figure-caption"><strong>Figure 7: <span class="margin-ref">Ramanujan<span class="margin-popup"><span class="popup-title">Ref [13]</span>Ramanujan, S. (1914). Modular equations and approximations to &#960;. <em>Quarterly Journal of Mathematics</em>, 45, 350&#8211;372. A mathematical prodigy whose insights seemed to bypass conventional derivation.<a class="popup-link" href="https://en.wikipedia.org/wiki/Srinivasa_Ramanujan" target="_blank" rel="noopener">Learn more &#8599;</a></span></span> problem levels.</strong> Each level requires deeper insight from less training data, producing higher CQ scores for conscious systems.</div>

<p>Problems inspired by Ramanujan cannot be solved by pattern matching alone&#8202;&#8212;&#8202;they require perceiving relationships not in the data. The degree of insight, relative to training, <em>is</em> CQ.</p>

<h3>A Turing Test for Consciousness</h3>

<p>Turing&#8217;s test measures conversational imitation. CQ measures <em>insight</em>. A system passing the Turing test with CQ $< 1$ is a mimic. A system with CQ $> 100$ on novel problems likely processes information in a way functionally equivalent to conscious insight.</p>

<!-- ═══ SECTION 8: OPEN QUESTIONS ═══ -->
<h2>Open Questions and Failure Modes</h2>

<p>While this theory covers decent ground in terms of framework development, there are still many areas that are open&#8202;&#8212;&#8202;and <span class="margin-ref">waiting to be worked on<span class="margin-popup"><span class="popup-title">Contribute</span>If you want to work on any of these areas, <a href="/cdn-cgi/l/email-protection#d7bfb097bba2bab2b9a5b2a4b2b6a5b4bff9b6be" style="color:var(--accent);text-decoration:none;border-bottom:1px solid var(--accent)">reach out to us</a>.</span></span>.</p>

<h3>The Problem of Compute</h3>
<p>Computing $\text{Sn}$ requires estimating joint Shannon information across all channels&#8202;&#8212;&#8202;a space growing exponentially with $n$ inputs. This may push real-time $\pi$ computation into EXPTIME territory. Mitigations include pairwise approximation, hierarchical compression, and attention-based sparsification.</p>
<div class="failure-mode"><strong>Failure mode:</strong> If real-time computation proves intractable even with approximations, the theory may be correct but unimplementable.</div>

<h3>The Problem of Architecture</h3>
<p>The theory specifies an objective but not the architecture. Open questions: What learning rule? Does consciousness require recurrence? Early or late fusion? How essential is physical embodiment?</p>
<div class="failure-mode"><strong>Failure mode:</strong> If the optimal architecture requires biological neural tissue, the theory explains biological consciousness without enabling artificial consciousness.</div>

<h3>The Problem of Memory Structure</h3>
<p>Memory is essential but underspecified. Biological memory is reconstructive, context-dependent, hierarchically organized. Which properties are essential? Is forgetting a bug or a feature? (Preliminary analysis: forgetting regularizes against overfitting.)</p>
<div class="failure-mode"><strong>Failure mode:</strong> If consciousness requires a specific memory architecture not derivable from $\pi$ minimization, the theory is incomplete.</div>

<h3>Universality</h3>
<p>Does every conscious system minimize $\pi$? Consciousness might arise through other mechanisms entirely.</p>
<div class="failure-mode"><strong>Failure mode:</strong> Conscious systems with high $\pi$, or unconscious systems with unexplainably low $\pi$, would break the universality claim.</div>

<h3>The Threshold Problem</h3>
<p>At what values of $\pi$, $\varphi$, and $C_{\text{capacity}}$ does consciousness emerge? Sharp transition or gradual continuum?</p>
<div class="failure-mode"><strong>Failure mode:</strong> If the transition depends on architecture rather than $\pi$ value, the theory loses predictive power about emergence.</div>

<h3>Distinguishing Low-Activity States</h3>
<p>The Rest quadrant contains phenomenologically distinct states. Practical measurement of $\varphi$ and $C_{\text{capacity}}$ with sufficient precision remains formidable.</p>
<div class="failure-mode"><strong>Failure mode:</strong> If $\varphi$ and $C_{\text{capacity}}$ cannot reliably distinguish meditation from sleep in practice, the state-space model is incomplete.</div>

<h3>The Limitations of Consciousness Testing</h3>
<p>The Consciousness Quotient is a useful probe but not a complete measure.</p>
<p><strong>Mathematical insight is one dimension, not all of it.</strong> Consciousness may involve aesthetic experience, emotional processing, self-awareness, or social cognition.</p>
<p><strong>CQ conflates consciousness with intelligence.</strong> A system might be conscious but unable to solve abstract problems.</p>
<p><strong>The test is anthropocentric.</strong> Consciousness in a different architecture might manifest in ways we cannot test.</p>
<p><strong>Performance metrics are indirect.</strong> CQ measures behavior, not internal states.</p>
<p>CQ should be understood as a <em>necessary condition</em>, not sufficient. A complete framework will require converging evidence: CQ (behavioral), $\pi$/$\varphi$/$C_{\text{capacity}}$ (computational), self-report quality (phenomenological), and perhaps yet-to-be-invented measurement approaches.</p>
<div class="failure-mode"><strong>Failure mode:</strong> If CQ measures intelligence rather than consciousness, the Insight Hypothesis is falsified and the measurement framework must be rethought.</div>

<!-- ═══ SECTION 9: FALSIFIABILITY ═══ -->
<h2>Falsifiability</h2>

<p>A theory that cannot be proven wrong is not a scientific theory.</p>

<h3>Conditions That Would Falsify the Theory</h3>

<ul>
<li><strong>$\pi$ does not decrease during learning.</strong> If a learning system shows no $\pi$ decrease, the core equation is wrong.</li>
<li><strong>$\pi$ and $\varphi$ are uncorrelated.</strong> If low $\pi$ coexists with low $\varphi$, the integration hypothesis fails.</li>
<li><strong>CQ does not discriminate.</strong> If CQ cannot distinguish conscious from unconscious systems, the metric is invalid.</li>
<li><strong>Unconscious systems achieve high CQ.</strong> If CQ $> 100$ is routinely achieved by unconscious systems, the Insight Hypothesis fails.</li>
<li><strong>$\pi$-optimized systems show no advantage.</strong> If $\pi$ minimization produces no improvement over $F$ minimization alone, the denominator adds nothing.</li>
</ul>

<!-- ═══ SECTION 10: CONCLUSION ═══ -->
<h2>Conclusion</h2>

<p>Cognitive Parsimony Theory proposes that conscious experience arises from optimizing predictive efficiency: $\pi = F/\text{Sn}$. Combined with $\varphi$ and $C_{\text{capacity}}$, it addresses why consciousness arises (the Climbing Problem), how it works (dual optimization), and how to measure it (CQ).</p>

<p>Its strengths: mathematical precision, testability, engineering applicability. It makes falsifiable predictions and suggests a next-generation AGI architecture.</p>

<p>Its weaknesses: computational tractability is uncertain, architecture is unspecified, memory is undertheorized, universality is unproven, and the threshold problem is open.</p>

<div class="callout">We offer this not as a complete theory, but as a mathematically precise, empirically testable starting point&#8202;&#8212;&#8202;one grounded in the ancient principle that <strong>nature favors the parsimonious</strong>.</div>

<!-- ═══ REFERENCES ═══ -->
<h2>References</h2>

<div class="ref-list">
<div class="ref-item"><span class="ref-num">1.</span><span>Baars, B. J. (1988). <em>A Cognitive Theory of Consciousness</em>. Cambridge University Press.</span></div>
<div class="ref-item"><span class="ref-num">2.</span><span>Casali, A. G., et al. (2013). A theoretically based index of consciousness independent of sensory processing and behavior. <em>Science Translational Medicine</em>, 5(198).</span></div>
<div class="ref-item"><span class="ref-num">3.</span><span>Chalmers, D. J. (1995). Facing up to the problem of consciousness. <em>Journal of Consciousness Studies</em>, 2(3), 200&#8211;219.</span></div>
<div class="ref-item"><span class="ref-num">4.</span><span>Clark, A. (2013). Whatever next? Predictive brains, situated agents, and the future of cognitive science. <em>Behavioral and Brain Sciences</em>, 36(3), 181&#8211;204.</span></div>
<div class="ref-item"><span class="ref-num">5.</span><span>Csikszentmihalyi, M. (1990). <em>Flow: The Psychology of Optimal Experience</em>. Harper &amp; Row.</span></div>
<div class="ref-item"><span class="ref-num">6.</span><span>Friston, K. (2010). The free-energy principle: A unified brain theory? <em>Nature Reviews Neuroscience</em>, 11(2), 127&#8211;138.</span></div>
<div class="ref-item"><span class="ref-num">7.</span><span>Friston, K., et al. (2017). Active inference, curiosity, and insight. <em>Neural Computation</em>, 29(10), 2633&#8211;2683.</span></div>
<div class="ref-item"><span class="ref-num">8.</span><span>Hafner, D., Pasukonis, J., Ba, J., &amp; Lillicrap, T. (2025). Mastering diverse control tasks through world models. <em>Nature</em>, 640, 647&#8211;653.</span></div>
<div class="ref-item"><span class="ref-num">9.</span><span>Kierkegaard, S. (1844/1980). <em>The Concept of Anxiety</em>. Princeton University Press.</span></div>
<div class="ref-item"><span class="ref-num">10.</span><span>Koch, C., et al. (2016). Neural correlates of consciousness: Progress and problems. <em>Nature Reviews Neuroscience</em>, 17(5), 307&#8211;321.</span></div>
<div class="ref-item"><span class="ref-num">11.</span><span>LeCun, Y. (2022). A path towards autonomous machine intelligence. <em>OpenReview</em> (preprint).</span></div>
<div class="ref-item"><span class="ref-num">12.</span><span>Oizumi, M., Albantakis, L., &amp; Tononi, G. (2014). From the phenomenology to the mechanisms of consciousness: IIT 3.0. <em>PLOS Computational Biology</em>, 10(5).</span></div>
<div class="ref-item"><span class="ref-num">13.</span><span>Ramanujan, S. (1914). Modular equations and approximations to $\pi$. <em>Quarterly Journal of Mathematics</em>, 45, 350&#8211;372.</span></div>
<div class="ref-item"><span class="ref-num">14.</span><span>Rao, R. P. N., &amp; Ballard, D. H. (1999). Predictive coding in the visual cortex. <em>Nature Neuroscience</em>, 2, 79&#8211;87.</span></div>
<div class="ref-item"><span class="ref-num">15.</span><span>Seth, A. K. (2014). A predictive processing theory of sensorimotor contingencies. <em>Cognitive Science</em>, 38(7), 1329&#8211;1353.</span></div>
<div class="ref-item"><span class="ref-num">16.</span><span>Shannon, C. E. (1948). A mathematical theory of communication. <em>Bell System Technical Journal</em>, 27(3), 379&#8211;423.</span></div>
<div class="ref-item"><span class="ref-num">17.</span><span>Tononi, G. (2004). An information integration theory of consciousness. <em>BMC Neuroscience</em>, 5, 42.</span></div>
<div class="ref-item"><span class="ref-num">18.</span><span>Tononi, G., et al. (2016). Integrated information theory: From consciousness to its physical substrate. <em>Nature Reviews Neuroscience</em>, 17(7), 450&#8211;461.</span></div>
</div>

<div class="paper-footer">
  <p><a href="index.html">Lumen Labs</a> &nbsp;&#183;&nbsp; February 2026</p>
</div>

</div>

<script>
(function() {
  // Theme toggle
  var htmlEl = document.documentElement;
  var toggleBtn = document.getElementById('themeToggle');
  var toggleKnob = document.getElementById('toggleKnob');

  function applyTheme(theme) {
    htmlEl.setAttribute('data-theme', theme);
    toggleKnob.textContent = theme === 'dark' ? '\u263D' : '\u2600';
  }

  toggleBtn.addEventListener('click', function() {
    var current = htmlEl.getAttribute('data-theme');
    applyTheme(current === 'dark' ? 'light' : 'dark');
  });

  applyTheme('dark');

  // Position popups in the left margin on hover
  var allRefs = document.querySelectorAll('.margin-ref, .def-term');
  
  allRefs.forEach(function(el) {
    var popup = el.querySelector('.margin-popup, .def-popup');
    if (!popup) return;
    
    el.addEventListener('mouseenter', function(e) {
      var rect = el.getBoundingClientRect();
      var container = document.querySelector('.paper-container');
      var containerRect = container.getBoundingClientRect();
      
      var leftSpace = containerRect.left;
      
      if (leftSpace > 280) {
        popup.style.left = (containerRect.left - 260) + 'px';
      } else {
        popup.style.left = rect.left + 'px';
      }
      
      var top = rect.top - 8;
      if (top + 300 > window.innerHeight) {
        top = window.innerHeight - 320;
      }
      if (top < 10) top = 10;
      popup.style.top = top + 'px';
      
      popup.style.display = 'block';
    });
    
    el.addEventListener('mouseleave', function(e) {
      setTimeout(function() {
        if (!el.matches(':hover') && !popup.matches(':hover')) {
          popup.style.display = 'none';
        }
      }, 800);
    });
    
    if (popup) {
      popup.addEventListener('mouseleave', function() {
        popup.style.display = 'none';
      });
    }
  });
})();
</script>
</body>
</html>